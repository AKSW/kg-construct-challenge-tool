#!/usr/bin/env python3

import os
import sys
import unittest
import requests
import warnings
import psycopg2
import pymysql
import subprocess
from container import Container
from rmlmapper import RMLMapper
from postgresql import PostgreSQL
from mysql import MySQL
from virtuoso import Virtuoso
from morphkgc import MorphKGC
from morphrdb import MorphRDB
from sdmrdfizer import SDMRDFizer
from ontop import OntopMaterialize, OntopVirtualize
from query import Query
from executor import Executor
from time import sleep
from rdflib import Graph

DATA_DIR = os.path.join(os.getcwd(), 'data')

class UnitTests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action='ignore', message='unclosed', category=ResourceWarning)

    def test_docker_run(self):
        c = Container('nginx:alpine', 'test_docker_run', {'80/tcp': '8080/tcp'})
        self.assertTrue(c.run())
        sleep(5)
        r = requests.get('http://localhost:8080')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()
        c.stop()

    def test_docker_run_and_wait_for_log(self):
        c = Container('nginx:alpine', 'test_docker_run_and_wait_for_log',
                      {'80/tcp': '8081/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        r = requests.get('http://localhost:8081')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()
        c.stop()

    def test_docker_run_and_wait_for_exit(self):
        c = Container('alpine:edge', 'test_docker_run_and_wait_for_exit',
                      {'80/tcp': '8082/tcp'})
        self.assertTrue(c.run_and_wait_for_exit('sleep 5'))
        c.stop()

    def test_docker_logs(self):
        c = Container('nginx:alpine', 'test_docker_logs',
                      {'80/tcp': '8083/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        self.assertIsNotNone(c.logs())
        self.assertTrue(len(c.logs()) > 0)
        c.stop()

    def test_docker_stats(self):
        c = Container('nginx:alpine', 'test_docker_stats',
                      {'80/tcp': '8084/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        stats1 = c.stats()

        # Trigger some activity
        for i in range(5):
            sleep(i)
            r = requests.get('http://localhost:8084')
            self.assertEqual(r.status_code, 200)
            r.raise_for_status()

        # Stats should be increased by now
        stats2 = c.stats()
        self.assertTrue(stats1['cpu']['total_cpu_time'] < stats2['cpu']['total_cpu_time'])

        c.stop()

    def test_postgresql(self):
        postgresql = PostgreSQL(DATA_DIR, False)
        self.assertTrue(postgresql.initialization())
        self.assertTrue(postgresql.wait_until_ready())
        connection = psycopg2.connect(host='localhost', database='db',
                                      user='root', password='root')
        cursor = connection.cursor()

        # Test valid query
        cursor.execute('SELECT 1;')

        # Test load CSV
        self.assertTrue(postgresql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        # Test invalid query
        with self.assertRaises(psycopg2.errors.UndefinedTable):
            cursor.execute('SELECT * FROM INVALID_TABLE;')
        connection.rollback()

        connection.close()
        postgresql.stop()

        # Check if the tables are really dropped
        postgresql = PostgreSQL(DATA_DIR, False)
        self.assertTrue(postgresql.wait_until_ready())
        connection = psycopg2.connect(host='localhost', user='root',
                                      password='root', database='db')
        cursor = connection.cursor()
        with self.assertRaises(psycopg2.errors.UndefinedTable):
            cursor.execute('SELECT name, age FROM student;')
        connection.rollback()

        # Check if we can now reload
        self.assertTrue(postgresql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        connection.close()
        postgresql.stop()

    def test_mysql(self):
        mysql = MySQL(DATA_DIR, False)
        self.assertTrue(mysql.initialization())
        self.assertTrue(mysql.wait_until_ready())
        connection = pymysql.connect(host='localhost', user='root',
                                     password='root', db='db')
        cursor = connection.cursor()

        # Test valid query
        cursor.execute('SELECT 1;')

        # Test load CSV
        self.assertTrue(mysql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        # Test invalid query
        with self.assertRaises(pymysql.err.ProgrammingError):
            cursor.execute('SELECT * FROM INVALID_TABLE;')

        # Close connection and stop container to drop all created tables
        connection.close()
        mysql.stop()

        # Check if the tables are really dropped
        mysql = MySQL(DATA_DIR, False)
        self.assertTrue(mysql.wait_until_ready())
        connection = pymysql.connect(host='localhost', user='root',
                                     password='root', db='db')
        cursor = connection.cursor()
        with self.assertRaises(pymysql.err.ProgrammingError):
            cursor.execute('SELECT name, age FROM student;')

        # Check if we can now reload
        self.assertTrue(mysql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        connection.close()
        mysql.stop()

class FileTests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action='ignore', message='unclosed', category=ResourceWarning)

    def test_rmlmapper_file(self):
        rmlmapper = RMLMapper(DATA_DIR, False)
        try:
            os.remove(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(rmlmapper.execute_mapping('/data/mapping.rml.ttl', '/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        rmlmapper.stop()

    def test_morphkgc_file(self):
        morphkgc = MorphKGC(DATA_DIR, False)
        try:
            os.remove(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(morphkgc.execute_mapping('/data/mapping.rml.ttl','/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphkgc', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        morphkgc.stop()

    def test_sdmrdfizer_file(self):
        sdmrdfizer = SDMRDFizer(DATA_DIR, False)
        try:
            os.remove(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(sdmrdfizer.execute_mapping('/data/mapping.rml.ttl','/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        sdmrdfizer.stop()


class RDBTests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action='ignore', message='unclosed', category=ResourceWarning)

    @classmethod
    def setUpClass(cls):
        cls._mysql = MySQL(DATA_DIR, False)
        cls._mysql.wait_until_ready()
        cls._mysql.load('student.csv', 'student')

        cls._postgresql = PostgreSQL(DATA_DIR, False)
        cls._postgresql.wait_until_ready()
        cls._postgresql.load('student.csv', 'student')

    @classmethod
    def tearDownClass(cls):
        cls._mysql.stop()
        cls._postgresql.stop()

    def test_rmlmapper_mysql(self):
        rmlmapper = RMLMapper(DATA_DIR, False)
        try:
            os.remove(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(rmlmapper.execute_mapping('/data/mapping.r2rml.ttl',
                                                  '/data/out.nt', 'ntriples',
                                                  'root', 'root', 'MySQL',
                                                  '3306', 'db', 'MySQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        rmlmapper.stop()

    def test_rmlmapper_postgresql(self):
        rmlmapper = RMLMapper(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(rmlmapper.execute_mapping('/data/mapping.r2rml.ttl',
                                                  '/data/out.nt', 'ntriples',
                                                  'root', 'root', 'PostgreSQL',
                                                  '5432', 'db', 'PostgreSQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        rmlmapper.stop()

    def test_morphkgc_mysql(self):
        morphkgc = MorphKGC(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(morphkgc.execute_mapping('/data/mapping.r2rml.ttl',
                                                 '/data/out.nt', 'ntriples',
                                                 'root', 'root', 'MySQL',
                                                 '3306', 'db', 'MySQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphkgc', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        morphkgc.stop()

    def test_morphkgc_postgresql(self):
        morphkgc = MorphKGC(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(morphkgc.execute_mapping('/data/mapping.r2rml.ttl',
                                                 '/data/out.nt', 'ntriples',
                                                 'root', 'root', 'PostgreSQL',
                                                 '5432', 'db', 'PostgreSQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphkgc', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        morphkgc.stop()

    def test_sdmrdfizer_mysql(self):
        sdmrdfizer = SDMRDFizer(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(sdmrdfizer.execute_mapping('/data/mapping.r2rml.ttl',
                                                   '/data/out.nt', 'ntriples',
                                                   'root', 'root', 'MySQL',
                                                   '3306', 'db', 'MySQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        sdmrdfizer.stop()

    def test_sdmrdfizer_postgresql(self):
        sdmrdfizer = SDMRDFizer(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(sdmrdfizer.execute_mapping('/data/mapping.r2rml.ttl',
                                                   '/data/out.nt', 'ntriples',
                                                   'root', 'root', 'PostgreSQL',
                                                   '5432', 'db', 'PostgreSQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        sdmrdfizer.stop()

    def test_ontopmaterialize_mysql(self):
        ontop = OntopMaterialize(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(ontop.execute_mapping('/data/mapping.r2rml.ttl',
                                              '/data/out.nt', 'ntriples',
                                              'root', 'root', 'MySQL',
                                              '3306', 'db', 'MySQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        ontop.stop()

    def test_ontopmaterialize_postgresql(self):
        ontop = OntopMaterialize(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(ontop.execute_mapping('/data/mapping.r2rml.ttl',
                                              '/data/out.nt', 'ntriples',
                                              'root', 'root', 'PostgreSQL',
                                              '5432', 'db', 'PostgreSQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'ontopmaterialize', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        ontop.stop()

    def test_ontopendpoint_mysql(self):
        ontop = OntopVirtualize(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'ontopendpoint', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(ontop.execute_mapping('/data/mapping.r2rml.ttl',
                                              '/data/out.nt', 'ntriples',
                                              'root', 'root', 'MySQL',
                                              '3306', 'db', 'MySQL'))
        # Verify loaded data
        q = Query(DATA_DIR, True)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8888/sparql')
        results = list(filter(None, results.split('\n')))
        # Ontop does not support N-Triples and returns only Turtle and other formats
        # For Turtle, 10 results are expect: 3 names and prefix definitions
        self.assertTrue(len(results) == 10)

        ontop.stop()

    def test_ontopendpoint_postgresql(self):
        ontop = OntopVirtualize(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'ontopendpoint', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(ontop.execute_mapping('/data/mapping.r2rml.ttl',
                                              '/data/out.nt', 'ntriples',
                                              'root', 'root', 'PostgreSQL',
                                              '5432', 'db', 'PostgreSQL'))
        # Verify loaded data
        q = Query(DATA_DIR, False)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8888/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 10)

        ontop.stop()

    def test_morphrdb_mysql(self):
        morphrdb = MorphRDB(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'morphrdb', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(morphrdb.execute_mapping('/data/mapping.r2rml.ttl',
                                                 '/data/out.nt', 'ntriples',
                                                 'root', 'root', 'MySQL',
                                                 '3306', 'db', 'MySQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphrdb', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphrdb', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        morphrdb.stop()

    def test_morphrdb_postgresql(self):
        morphrdb = MorphRDB(DATA_DIR, True)
        try:
            os.remove(os.path.join(DATA_DIR, 'morphrdb', 'out.nt'))
        except FileNotFoundError:
            pass
        self.assertTrue(morphrdb.execute_mapping('/data/mapping.r2rml.ttl',
                                                 '/data/out.nt', 'ntriples',
                                                 'root', 'root', 'PostgreSQL',
                                                 '5432', 'db', 'PostgreSQL'))

        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphrdb', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphrdb', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)

        morphrdb.stop()


class TriplestoreTests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action='ignore', message='unclosed', category=ResourceWarning)

    def test_virtuoso(self):
        virtuoso = Virtuoso(DATA_DIR, False)
        self.assertTrue(virtuoso.initialization())
        self.assertTrue(virtuoso.wait_until_ready())

        # Check if web interface is up
        r = requests.get('http://localhost:8890')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()

        # Check if SPARQL endpoint works
        r = requests.get('http://localhost:8890/sparql/?default-graph-uri=&query=CONSTRUCT+WHERE+%7B%0D%0A++%3Fs+%3Fp+%3Fo.%0D%0A%7D%0D%0ALIMIT+100&format=text%2Fplain')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()

        # Check if iSQL is up, HTTP is unsupported on the iSQL port
        # so the connection will be closed without a response
        with self.assertRaises(requests.exceptions.ConnectionError) as e:
            r = requests.get('http://localhost:1111')
            r.raise_for_status()
        self.assertTrue('Connection aborted' in str(e.exception))

        # Test load RDF
        self.assertTrue(virtuoso.load('student.nt'))

        # Verify loaded data
        q = Query(DATA_DIR, False)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8890/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 3)

        # RDF is dropped when container is stopped
        virtuoso.stop()

        # Virtuoso is already initialized only wait for it to be ready
        virtuoso = Virtuoso(DATA_DIR, False)
        self.assertTrue(virtuoso.wait_until_ready())

        # Verify removed data
        q = Query(DATA_DIR, False)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8890/sparql')
        self.assertTrue('# Empty NT' in results)

        # Test if we can now reload our RDF
        self.assertTrue(virtuoso.load('student.nt'))

        # Verify loaded data
        q = Query(DATA_DIR, False)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8890/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 3)

        virtuoso.stop()

    def test_query(self):
        q = Query(DATA_DIR, False)
        results = q.execute('CONSTRUCT WHERE { ?s ?p ?o. } LIMIT 100',
                            'https://dbpedia.org/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 100)

class IntegrationTests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action='ignore', message='unclosed', category=ResourceWarning)

    def test_executor_list(self):
        executor = Executor(os.path.join(DATA_DIR, 'cases'), False)
        cases = executor.list()
        iris = [x['data']['@id'] for x in cases]
        self.assertListEqual(['http://dylanvanassche.be/cases/transform-csv-to-ntriples',
                              'http://dylanvanassche.be/cases/transform-mysql-to-ntriples',
                              'http://dylanvanassche.be/cases/transform-postgresql-to-ntriples'], iris)

    def test_executor_run(self):
        path = os.path.join(DATA_DIR, 'cases')
        executor = Executor(path, False)

        for case in executor.list():
            # Clean case
            executor.clean(case)

            # Check if all files are removed
            for step in case['data']['steps']:
                name = case['data']['name']
                resource = step['resource']
                root_mount_directory = resource.lower().replace('_', '')
                log_file = os.path.join(path, name, 'data', root_mount_directory,
                                        'logs.txt')
                checkpoint_file = os.path.join(path, name, '.done')
                metrics_file = os.path.join(path, name, 'data', root_mount_directory,
                                            'metrics.jsonl')

                self.assertFalse(os.path.exists(log_file))
                self.assertFalse(os.path.exists(metrics_file))
                self.assertFalse(os.path.exists(checkpoint_file))

            # Run case
            self.assertTrue(executor.run(case, 0.1, 1, True))

            # Check if all files are generated
            for step in case['data']['steps']:
                name = case['data']['name']
                resource = step['resource']
                root_mount_directory = resource.lower().replace('_', '')
                log_file = os.path.join(path, name, 'results', 'run_1',
                                        root_mount_directory, 'logs.txt')
                checkpoint_file = os.path.join(path, name, '.done')
                metrics_file = os.path.join(path, name, 'results', 'run_1',
                                            root_mount_directory,
                                            'metrics.jsonl')

                # Verify if log, checkpoint, metrics files exists
                # Log files are expected to contain at least 1 line,
                # Metrics files at least 3: START, MEASUREMENT, STOP types, and
                # Checkpoint files contain a single line with the timestamp
                self.assertTrue(os.path.exists(log_file))
                with open(log_file) as f:
                    self.assertTrue(len(f.readlines()) > 0)
                self.assertTrue(os.path.exists(metrics_file))
                with open(metrics_file) as f:
                    lines = f.readlines()
                    # Query execution is not done with a Docker container so
                    # no stats available about resource consumption
                    if 'query' in metrics_file:
                        self.assertTrue(len(lines) == 2)
                        self.assertTrue('START' in lines[0])
                        self.assertTrue('STOP' in lines[-1])
                    else:
                        self.assertTrue(len(lines) >= 4)
                        self.assertTrue('START' in lines[0])
                        self.assertTrue('INIT' in lines[1])
                        self.assertTrue('MEASUREMENT' in lines[2])
                        self.assertTrue('cpu' in lines[2])
                        self.assertTrue('memory' in lines[2])
                        self.assertTrue('io' in lines[2])
                        self.assertTrue('network' in lines[2])
                        self.assertTrue('STOP' in lines[-1])

                self.assertTrue(os.path.exists(checkpoint_file))
                with open(checkpoint_file) as f:
                    self.assertTrue(len(f.readlines()) == 1)

if __name__ == '__main__':
    # SELinux causes weird permission denied issues, warn users
    try:
        response = subprocess.check_output('getenforce')
        if response.decode().strip() != 'Permissive':
            print('SELinux must be set to "permissive" to allow containers '
                  'accessing files in mounted directories', file=sys.stderr)
            sys.exit(-1)
    except subprocess.CalledProcessError:
        pass

    if len(sys.argv) > 1:
        unittest.main()
    else:
        print('*' * 3 + ' UNIT TESTS ' + '*' * 3)
        unittest.main(defaultTest='UnitTests', exit=False)
        print('*' * 3 + ' FILE TESTS ' + '*' * 3)
        unittest.main(defaultTest='FileTests', exit=False)
        print('*' * 3 + ' RDB TESTS ' + '*' * 3)
        unittest.main(defaultTest='RDBTests', exit=False)
        print('*' * 3 + ' TRIPLE STORE TESTS ' + '*' * 3)
        unittest.main(defaultTest='TriplestoreTests', exit=False)
        print('*' * 3 + 'INTEGRATION TESTS' + '*' * 3)
        unittest.main(defaultTest='IntegrationTests')
