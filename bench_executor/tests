#!/usr/bin/env python3

import os
import sys
import unittest
import requests
import warnings
import psycopg2
import pymysql
import subprocess
from container import Container
from rmlmapper import RMLMapper
from postgresql import PostgreSQL
from mysql import MySQL
from virtuoso import Virtuoso
from morphkgc import MorphKGC
from sdmrdfizer import SDMRDFizer
from query import Query
from executor import Executor
from time import sleep
from rdflib import Graph

DATA_DIR = os.path.join(os.getcwd(), 'data')

class Unittests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action="ignore", message="unclosed", category=ResourceWarning)

    def test_docker_run(self):
        c = Container('nginx:alpine', 'test_docker_run', {'80/tcp': '8080/tcp'})
        self.assertTrue(c.run())
        sleep(5)
        r = requests.get('http://localhost:8080')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()
        c.stop()

    def test_docker_run_and_wait_for_log(self):
        c = Container('nginx:alpine', 'test_docker_run_and_wait_for_log',
                      {'80/tcp': '8081/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        r = requests.get('http://localhost:8081')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()
        c.stop()

    def test_docker_run_and_wait_for_exit(self):
        c = Container('alpine:edge', 'test_docker_run_and_wait_for_exit',
                      {'80/tcp': '8082/tcp'})
        self.assertTrue(c.run_and_wait_for_exit('sleep 5'))
        c.stop()

    def test_docker_logs(self):
        c = Container('nginx:alpine', 'test_docker_logs',
                      {'80/tcp': '8083/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        self.assertIsNotNone(c.logs())
        self.assertTrue(len(c.logs()) > 0)
        c.stop()

    def test_docker_stats(self):
        c = Container('nginx:alpine', 'test_docker_stats',
                      {'80/tcp': '8084/tcp'})
        self.assertTrue(c.run_and_wait_for_log('start worker process'))
        stats1 = c.stats()

        # Trigger some activity
        for i in range(5):
            sleep(i)
            r = requests.get('http://localhost:8084')
            self.assertEqual(r.status_code, 200)
            r.raise_for_status()

        # Stats should be increased by now
        stats2 = c.stats()
        self.assertTrue(stats1['cpu']['total_cpu_time'] < stats2['cpu']['total_cpu_time'])

        c.stop()

    def test_rmlmapper_file(self):
        rmlmapper = RMLMapper(DATA_DIR, False)
        self.assertTrue(rmlmapper.execute_mapping('/data/mapping.rml.ttl', '/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'rmlmapper', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        rmlmapper.stop()

    def test_morphkgc_file(self):
        morphkgc = MorphKGC(DATA_DIR, False)
        self.assertTrue(morphkgc.execute_mapping('/data/mapping.rml.ttl','/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'morphkgc', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'morphkgc', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        morphkgc.stop()

    def test_sdmrdfizer_file(self):
        sdmrdfizer = SDMRDFizer(DATA_DIR, False)
        self.assertTrue(sdmrdfizer.execute_mapping('/data/mapping.rml.ttl','/data/out.nt', 'ntriples'))
        self.assertTrue(os.path.exists(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt')))
        g = Graph()
        g.parse(os.path.join(DATA_DIR, 'sdmrdfizer', 'out.nt'), format='ntriples')
        self.assertEqual(len(g), 3)
        sdmrdfizer.stop()

    def test_postgresql(self):
        postgresql = PostgreSQL(DATA_DIR, False)
        self.assertTrue(postgresql.wait_until_ready())
        connection = psycopg2.connect(host='localhost', database='db',
                                      user='root', password='root')
        cursor = connection.cursor()

        # Test valid query
        cursor.execute('SELECT 1;')

        # Test load CSV
        self.assertTrue(postgresql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        # Test invalid query
        with self.assertRaises(psycopg2.errors.UndefinedTable):
            cursor.execute('SELECT * FROM INVALID_TABLE;')

        connection.close()
        postgresql.stop()

    def test_mysql(self):
        mysql = MySQL(DATA_DIR, False)
        self.assertTrue(mysql.wait_until_ready())
        connection = pymysql.connect(host='localhost', user='root',
                                     password='root', db='db')
        cursor = connection.cursor()

        # Test valid query
        cursor.execute('SELECT 1;')

        # Test load CSV
        self.assertTrue(mysql.load('student.csv', 'student'))
        cursor.execute('SELECT name, age FROM student;')
        results = []
        for record in cursor:
            results.append([record[0], record[1]])
        self.assertListEqual(results, [['Jefke', '21'], ['Maria', '22'], ['Jos', '23']])

        # Test invalid query
        with self.assertRaises(pymysql.err.ProgrammingError):
            cursor.execute('SELECT * FROM INVALID_TABLE;')

        connection.close()
        mysql.stop()

    def test_virtuoso(self):
        virtuoso = Virtuoso(DATA_DIR, False)
        self.assertTrue(virtuoso.wait_until_ready())

        # Check if web interface is up
        r = requests.get('http://localhost:8890')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()

        # Check if SPARQL endpoint works
        r = requests.get('http://localhost:8890/sparql/?default-graph-uri=&query=CONSTRUCT+WHERE+%7B%0D%0A++%3Fs+%3Fp+%3Fo.%0D%0A%7D%0D%0ALIMIT+100&format=text%2Fplain')
        self.assertEqual(r.status_code, 200)
        r.raise_for_status()

        # Check if iSQL is up, HTTP is unsupported on the iSQL port
        # so the connection will be closed without a response
        with self.assertRaises(requests.exceptions.ConnectionError) as e:
            r = requests.get('http://localhost:1111')
            r.raise_for_status()
        self.assertTrue('Connection aborted' in str(e.exception))

        # Test load RDF
        self.assertTrue(virtuoso.load('student.nt'))

        # Verify loaded data
        q = Query(DATA_DIR, False)
        results = q.execute('PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT WHERE { ?s foaf:name ?o1 . }',
                            'http://localhost:8890/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 3)

        virtuoso.stop()

    def test_query(self):
        q = Query(DATA_DIR, False)
        results = q.execute('CONSTRUCT WHERE { ?s ?p ?o. } LIMIT 100',
                            'https://dbpedia.org/sparql')
        results = list(filter(None, results.split('\n')))
        self.assertTrue(len(results) == 100)

class Integrationtests(unittest.TestCase):
    def setUp(self):
        warnings.filterwarnings(action="ignore", message="unclosed", category=ResourceWarning)

    def test_executor_list(self):
        executor = Executor(os.path.join(DATA_DIR, 'cases'), False)
        cases = executor.list()
        iris = [x['data']['@id'] for x in cases]
        self.assertListEqual(['http://dylanvanassche.be/cases/transform-csv-to-ntriples',
                              'http://dylanvanassche.be/cases/transform-mysql-to-ntriples',
                              'http://dylanvanassche.be/cases/transform-postgresql-to-ntriples'], iris)

    def test_executor_run(self):
        path = os.path.join(DATA_DIR, 'cases')
        executor = Executor(path, False)

        for case in executor.list():
            # Clean case
            executor.clean(case)

            # Check if all files are removed
            for step in case['data']['steps']:
                name = case['data']['name']
                resource = step['resource']
                root_mount_directory = resource.lower().replace('_', '')
                log_file = os.path.join(path, name, 'data', root_mount_directory,
                                        'logs.txt')
                checkpoint_file = os.path.join(path, name, '.done')
                metrics_file = os.path.join(path, name, 'data', root_mount_directory,
                                            'metrics.jsonl')

                self.assertFalse(os.path.exists(log_file))
                self.assertFalse(os.path.exists(metrics_file))
                self.assertFalse(os.path.exists(checkpoint_file))

            # Run case
            self.assertTrue(executor.run(case, 0.25, 1, True))

            # Check if all files are generated
            for step in case['data']['steps']:
                name = case['data']['name']
                resource = step['resource']
                root_mount_directory = resource.lower().replace('_', '')
                log_file = os.path.join(path, name, 'results', str(1),
                                        root_mount_directory, 'logs.txt')
                checkpoint_file = os.path.join(path, name, '.done')
                metrics_file = os.path.join(path, name, 'results', str(1),
                                            root_mount_directory,
                                            'metrics.jsonl')

                # Verify if log, checkpoint, metrics files exists
                # Log files are expected to contain at least 1 line,
                # Metrics files at least 3: START, MEASUREMENT, STOP types, and
                # Checkpoint files contain a single line with the timestamp
                self.assertTrue(os.path.exists(log_file))
                with open(log_file) as f:
                    self.assertTrue(len(f.readlines()) > 0)
                self.assertTrue(os.path.exists(metrics_file))
                with open(metrics_file) as f:
                    lines = f.readlines()
                    # Query execution is not done with a Docker container so
                    # no stats available about resource consumption
                    if 'query' in metrics_file:
                        self.assertTrue(len(lines) == 2)
                        self.assertTrue('START' in lines[0])
                        self.assertTrue('STOP' in lines[-1])
                    else:
                        self.assertTrue(len(lines) >= 3)
                        self.assertTrue('START' in lines[0])
                        self.assertTrue('MEASUREMENT' in lines[1])
                        self.assertTrue('STOP' in lines[-1])

                self.assertTrue(os.path.exists(checkpoint_file))
                with open(checkpoint_file) as f:
                    self.assertTrue(len(f.readlines()) == 1)

if __name__ == '__main__':
    # SELinux causes weird permission denied issues, warn users
    try:
        response = subprocess.check_output('getenforce')
        if response.decode().strip() != 'Permissive':
            print('SELinux must be set to "permissive" to allow containers '
                  'accessing files in mounted directories', file=sys.stderr)
            sys.exit(-1)
    except subprocess.CalledProcessError:
        pass

    if len(sys.argv) > 1:
        unittest.main()
    else:
        print('*' * 3 + ' UNIT TESTS ' + '*' * 3)
        unittest.main(defaultTest='Unittests', exit=False)
        print('*' * 3 + 'INTEGRATION TESTS' + '*' * 3)
        unittest.main(defaultTest='Integrationtests')

